{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NATURAL LANGUAGE PROCESSING\n",
    "\n",
    "\n",
    "The goal of NLP is to deal with interactions between humans and computer using Natural Language. It is broadly defined as the automatic manipulation of natural language and also used to make the text analyzable. The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
    "\n",
    "![title](images/nlp_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WHY NATURAL LANGUAGE PROCESSING\n",
    "\n",
    "Natural Language Processing is a very old field and has grown rapidly with the advancement of technology, particulary because of the evolution of Big Data. Since the last decade we have seen an exponential amount of increase in data volumes. Text is almost everywhere, all of your documents, online blogs, every single website on internet is a combination of 70-80% text and 20-30% images. \n",
    "\n",
    "![title](images/annual_size_of_data.png)\n",
    "\n",
    "## 2.1 - Applications of NLP\n",
    "\n",
    "NLP is the need of almost every industry. Each second millions of GBs of new text is generated in the world. There are tons of Industrial Applications of NLP:\n",
    "\n",
    "1. Chat-bots\n",
    "2. Sentiment Analysis\n",
    "3. Text Summarization\n",
    "4. Fake Text Detection\n",
    "5. Spam Emails\n",
    "6. Text classification\n",
    "7. Bots Solving Question Answering Problems\n",
    "8. Search Enginer Optimization Tags\n",
    "9. Image to Captions\n",
    "10. Audio to Text Mapping\n",
    "11. Machine Translation\n",
    "12. Text Recommendation in Mobile Keyboards\n",
    "\n",
    "There are hundreds and thousands of more applications of NLP that can be named. Almost every application is either using NLP or has the prospect to have NLP integrated it with.\n",
    "\n",
    "![title](images/nlp_applications.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CHALLENGE OF NATURAL LANGUAGE\n",
    "\n",
    "Dealing with textual data is one of the most difficult and complex task of Machine Learning and Information Retrieval. Quoting a secion from **Neural Network Methods in Natural Language Processing, 2017.**\n",
    "\n",
    "<blockquote>\"Human language is highly ambiguous … It is also ever changing and evolving. People are great at producing language and understanding language, and are capable of expressing, perceiving, and interpreting very elaborate and nuanced meanings. At the same time, while we humans are great users of language, we are also very poor at formally understanding and describing the rules that govern language.\"</blockquote>\n",
    "\n",
    "Natural Language is basically complex because it is messy.\n",
    "\n",
    "## 3.1 - Machines Interpreting Text\n",
    "\n",
    "Besides the complexity of understanding the contextual, syntactic, semantic and ambiguities of text. The biggest question is how are we gonna make our machines understand text. Text is just a Byte string and computers are only good at understanding numbers and patterns. Now the biggest question is how machines are going to understand all these complexities of Language using these RAW STRINGS.\n",
    "\n",
    "![title](images/text_and_machines.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CASE STUDY: FAKE INFORMATION\n",
    "\n",
    "Internet is one of the most important thing of this century. Whenever or whatever you think or looking for is just one search away. There is tons of information available at the websites. There are millions of blogs, wikis, social media platforms, and other reference websites for any kind of thing you are looking for. But with all big things comes its own problems. One of the biggest issue is that there is no check and balance of information available at Internet. This issue particularly matters a lot when it comes to NEWS data. News builds a persons opinion and awareness, So it is really important to have this evaluated.\n",
    "\n",
    "## 4.1 - Fake News dataset\n",
    "\n",
    "I have picked a similar problem to this and found a related dataset at Kaggel: https://www.kaggle.com/mrisdal/fake-news . \n",
    "\n",
    "The dataset contains text and metadata from 244 websites and represents 12,999 posts in total from the past 30 days. The data was pulled using the webhose.io API; because it's coming from their crawler, not all websites identified by the BS Detector are present in this dataset. Each website was labeled according to the BS Detector as documented here. Data sources that were missing a label were simply assigned a label of \"bs\". There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don't trust anything you read.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Let's start with our imports. Here we are importing TensorFlow to build a deep learning model.\n",
    "\n",
    "gensim library for text cleaning and loading word_emebddings\n",
    "\n",
    "pandas for reading data file and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Text8Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Lets start with loading and analysis of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>ord_in_thread</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>crawled</th>\n",
       "      <th>site_url</th>\n",
       "      <th>country</th>\n",
       "      <th>domain_rank</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>participants_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
       "      <td>0</td>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid  ord_in_thread  \\\n",
       "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
       "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
       "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
       "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
       "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
       "\n",
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  Print They should pay all the back all the mon...  english   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
       "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
       "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
       "\n",
       "                         crawled             site_url country  domain_rank  \\\n",
       "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
       "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
       "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
       "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
       "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
       "\n",
       "                                        thread_title  spam_score  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
       "\n",
       "                                        main_img_url  replies_count  \\\n",
       "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "\n",
       "   participants_count  likes  comments  shares  type  \n",
       "0                   1      0         0       0  bias  \n",
       "1                   1      0         0       0  bias  \n",
       "2                   1      0         0       0  bias  \n",
       "3                   0      0         0       0  bias  \n",
       "4                   0      0         0       0  bias  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news = pd.read_csv(\"fake.csv\")\n",
    "fake_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Data\n",
    "\n",
    "pandas describe functions gives you a basic analysis of the numerical columns avaialble in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_in_thread</th>\n",
       "      <th>domain_rank</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>participants_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12999.000000</td>\n",
       "      <td>8776.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "      <td>12999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891530</td>\n",
       "      <td>38092.996582</td>\n",
       "      <td>0.026122</td>\n",
       "      <td>1.383183</td>\n",
       "      <td>1.727518</td>\n",
       "      <td>10.831833</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>10.831833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.486822</td>\n",
       "      <td>26825.487454</td>\n",
       "      <td>0.122889</td>\n",
       "      <td>9.656838</td>\n",
       "      <td>6.884239</td>\n",
       "      <td>79.798949</td>\n",
       "      <td>0.827335</td>\n",
       "      <td>79.798949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17423.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>34478.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60570.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>98679.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>988.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ord_in_thread   domain_rank    spam_score  replies_count  \\\n",
       "count   12999.000000   8776.000000  12999.000000   12999.000000   \n",
       "mean        0.891530  38092.996582      0.026122       1.383183   \n",
       "std         6.486822  26825.487454      0.122889       9.656838   \n",
       "min         0.000000    486.000000      0.000000       0.000000   \n",
       "25%         0.000000  17423.000000      0.000000       0.000000   \n",
       "50%         0.000000  34478.000000      0.000000       0.000000   \n",
       "75%         0.000000  60570.000000      0.000000       0.000000   \n",
       "max       100.000000  98679.000000      1.000000     309.000000   \n",
       "\n",
       "       participants_count         likes      comments        shares  \n",
       "count        12999.000000  12999.000000  12999.000000  12999.000000  \n",
       "mean             1.727518     10.831833      0.038311     10.831833  \n",
       "std              6.884239     79.798949      0.827335     79.798949  \n",
       "min              0.000000      0.000000      0.000000      0.000000  \n",
       "25%              1.000000      0.000000      0.000000      0.000000  \n",
       "50%              1.000000      0.000000      0.000000      0.000000  \n",
       "75%              1.000000      0.000000      0.000000      0.000000  \n",
       "max            240.000000    988.000000     65.000000    988.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>number_of_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admin</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakalert</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gillian</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Editor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eddy Lavine</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.E. Dyer</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>voltairenet.org</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tomás Fuentes</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td># 1 NWO Hatr</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Robert Rich</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             author  number_of_news\n",
       "0             admin             247\n",
       "1          Pakalert             100\n",
       "2           Gillian             100\n",
       "3            Editor             100\n",
       "4       Eddy Lavine             100\n",
       "..              ...             ...\n",
       "95        J.E. Dyer              23\n",
       "96  voltairenet.org              23\n",
       "97    Tomás Fuentes              22\n",
       "98     # 1 NWO Hatr              22\n",
       "99      Robert Rich              22\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_authors = 100\n",
    "fake_news.groupby(\"author\").count()[[\"uuid\"]].sort_values(by=\"uuid\", ascending=False).reset_index().rename(columns={\"uuid\": \"number_of_news\"})[:top_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = fake_news[[\"text\", \"spam_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Very Short Size News\n",
    "\n",
    "Lets remove all the news from dataset which are very short in length, since with a limited text our machine will not be able to build a better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = fake_news[fake_news.text.str.len() > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Histogram function\n",
    "\n",
    "Pandas histogram function is a very useful function to do a histogram analysis. It automatically generates the histograms for all the numerical data in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f826fca9588>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_news.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Unbalanced\n",
    "\n",
    "It can be seen that there exists a very high unbalancing between spam and non-spam news. In order to solve it, for simplicity lets reduce (under-sample) our non-spam news dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_good_news_sample = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f826f988358>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([fake_news[fake_news.spam_score < 0.1].sample(frac=pick_good_news_sample), fake_news[fake_news.spam_score >= 0.1]], ignore_index=True).sample(frac=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>The storm before the calm before the storm • S...</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>What Lessons America Can Learn From This Elect...</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>New Heavy-Duty Voting Machine Allows Americans...</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>By Daily News Bin | November 3, 2016 | 2 947 S...</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>Страна: Ирак Как отмечает в своей новой статье...</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam_score\n",
       "1063  The storm before the calm before the storm • S...       0.608\n",
       "1144  What Lessons America Can Learn From This Elect...       0.953\n",
       "1092  New Heavy-Duty Voting Machine Allows Americans...       0.384\n",
       "660   By Daily News Bin | November 3, 2016 | 2 947 S...       0.200\n",
       "861   Страна: Ирак Как отмечает в своей новой статье...       0.219"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.concat([fake_news[fake_news.spam_score < 0.1].sample(frac=pick_good_news_sample), fake_news[fake_news.spam_score >= 0.1]], ignore_index=True).sample(frac=1)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Text Analysis\n",
    "\n",
    "So far we only have done a general data analysis, but we still have the main issue of dealing with text. Lets start step-by-step analysis of Text:\n",
    "\n",
    "### 4.2.1 - Stopwords\n",
    "\n",
    "A stop word is a commonly used word (such as “the”, “a”, “an”, “in”, \"and\"). They are highly frequent words and don't have any definitive meaning. Famous libraries for NLP like NLTK, SpaCy, and gensim provides us with a set of stopwords to remove:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 - Frequency Analysis on whole corpus\n",
    "\n",
    "A raw text is a combination of multiple sentences and each sentence is compromised of multiple tokens and words. It is important to do a frequency analysis of our corpus to see what other words besides stopwords are coming very frequently. This helps you to build up an intution about the domain and understanding about your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.1 - Regex\n",
    "\n",
    "A regular expression (also sometimes called a rational expression) is a special set of characters that define a Search Pattern.\n",
    "\n",
    "For example if we need to only pick valid character words from our corpus we can use this regex pattern: \"[a-zA-Z]{2,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.2 - N-grams\n",
    "\n",
    "A word token can be a uni-gram, bi-gram, tri-gram or an N-gram. N-grams are conceptual units. \n",
    "\n",
    "e.g. New York is a bi-gram and it only makes sense when new and york are combined as 1 unit. \n",
    "\n",
    "### Get Into Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "total_corpus = \" \".join(final_data[\"text\"].tolist())\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', min_df=1, stop_words=\"english\", \n",
    "                             token_pattern=\"[a-zA-Z]{3,}\", ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform([total_corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see in how many tokens our corpus has been tokenized using the applied regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_freq = Counter(dict(zip(vectorizer.get_feature_names(), list(X.toarray()[0, :]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 2738),\n",
       " ('clinton', 2092),\n",
       " ('people', 1640),\n",
       " ('hillary', 1613),\n",
       " ('said', 1521),\n",
       " ('new', 1323),\n",
       " ('just', 1281),\n",
       " ('like', 1203),\n",
       " ('time', 1109),\n",
       " ('president', 1045),\n",
       " ('election', 1006),\n",
       " ('russia', 1003),\n",
       " ('state', 981),\n",
       " ('world', 905),\n",
       " ('states', 883),\n",
       " ('government', 862),\n",
       " ('american', 856),\n",
       " ('war', 812),\n",
       " ('obama', 811),\n",
       " ('media', 791),\n",
       " ('hillary clinton', 759),\n",
       " ('news', 753),\n",
       " ('donald', 710),\n",
       " ('years', 708),\n",
       " ('country', 688),\n",
       " ('political', 673),\n",
       " ('donald trump', 672),\n",
       " ('united', 666),\n",
       " ('russian', 652),\n",
       " ('campaign', 650),\n",
       " ('america', 631),\n",
       " ('way', 624),\n",
       " ('know', 609),\n",
       " ('military', 605),\n",
       " ('year', 605),\n",
       " ('right', 590),\n",
       " ('day', 579),\n",
       " ('make', 571),\n",
       " ('going', 564),\n",
       " ('think', 555),\n",
       " ('united states', 540),\n",
       " ('white', 536),\n",
       " ('que', 535),\n",
       " ('did', 530),\n",
       " ('national', 526),\n",
       " ('don', 524),\n",
       " ('americans', 520),\n",
       " ('presidential', 510),\n",
       " ('washington', 506),\n",
       " ('fbi', 494)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Before moving forward lets split our dataset into train and test in order to train a prediction model and its evaluation. Lets pick a 15% test dataset and keep 85% for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data[\"text\"].values, final_data[\"spam_score\"].values, test_size=0.15, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Text Representation\n",
    "\n",
    "Machine Learning models only understand numerical values in order to learn models and perform computations. We need to convert our textual information in some kind of numerical representations so that we can train a predictive model for this task. There are 2 common-methods to represent our text in numerical values:\n",
    "\n",
    "1. Bag of Words Model\n",
    "2. Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 - Bag of Words Model\n",
    "\n",
    "In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. \n",
    "\n",
    "Lets use one of the most common, effective and famous bag of words model: **tf-idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1.1 - tf-idf\n",
    "\n",
    "A tf-idf model represents your dataset in the form of a DOCUMENTxWORD_TOKENS matrix. Each corresponding value is calculated usign the formula tf*idf.\n",
    "\n",
    "1. tf: Number times a word_token comes in a particular document/news\n",
    "2. df: Number of times a word_token comes in the documents\n",
    "3. idf: inverse of document frequence (1/df)\n",
    "\n",
    "\n",
    "In our case, document is each nexs text and term frequency is calculated based on the number of times a word comes within that text\n",
    "\n",
    "\n",
    "![title](images/tf_idf_matrix.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(analyzer='word', min_df=5, stop_words=\"english\",\n",
    "                                    token_pattern=\"[a-zA-Z]{3,}\", ngram_range=(1, 3))\n",
    "\n",
    "X_train_tfidf = tf_idf_vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Compile the Neural Network\n",
    "\n",
    "Lets define a very simple neural netwrok to solve this task:\n",
    "\n",
    "![title](images/basic_neural_network_prob_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(3, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential:** That defines a SEQUENCE of layers in the neural network\n",
    "\n",
    "**Dense:** Adds a layer of neurons\n",
    "\n",
    "Each layer of neurons need an activation function to tell them what to do. There's lots of options, like tanh, relu, sigmoid and many more.\n",
    "\n",
    "\n",
    "Now we compile our Neural Network. When we do so, we have to specify 2 functions, a loss and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizers=\"sgd\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n",
    "\n",
    "The process of training the neural network, where it 'learns' the relationship between the Xs and Ys is in the model.fit call. This is where it will go through the loop we spoke about above, making a guess, measuring how good or bad it is (aka the loss), using the opimizer to make another guess etc. It will do it for the number of epochs you specify. When you run this code, you'll see the loss on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1117 samples\n",
      "Epoch 1/10\n",
      "1117/1117 [==============================] - 1s 690us/sample - loss: 0.1326 - accuracy: 0.4145\n",
      "Epoch 2/10\n",
      "1117/1117 [==============================] - 0s 102us/sample - loss: 0.1042 - accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "1117/1117 [==============================] - 0s 108us/sample - loss: 0.0919 - accuracy: 0.4199\n",
      "Epoch 4/10\n",
      "1117/1117 [==============================] - 0s 104us/sample - loss: 0.0858 - accuracy: 0.4199\n",
      "Epoch 5/10\n",
      "1117/1117 [==============================] - 0s 103us/sample - loss: 0.0821 - accuracy: 0.4199\n",
      "Epoch 6/10\n",
      "1117/1117 [==============================] - 0s 104us/sample - loss: 0.0790 - accuracy: 0.4199\n",
      "Epoch 7/10\n",
      "1117/1117 [==============================] - 0s 106us/sample - loss: 0.0758 - accuracy: 0.4199\n",
      "Epoch 8/10\n",
      "1117/1117 [==============================] - 0s 102us/sample - loss: 0.0721 - accuracy: 0.4199\n",
      "Epoch 9/10\n",
      "1117/1117 [==============================] - 0s 101us/sample - loss: 0.0678 - accuracy: 0.4199\n",
      "Epoch 10/10\n",
      "1117/1117 [==============================] - 0s 111us/sample - loss: 0.0626 - accuracy: 0.4199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f826f30b780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tfidf.todense(), y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating your Model\n",
    "\n",
    "Once we have trained our model on a specific dataset, now the most important goal is to evaluate our trained model on the test dataset to make sure if it can now perform good on unseen data as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117, 12043)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = tf_idf_vectorizer.transform(X_test)\n",
    "X_train_tfidf.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  9.070580430103071  |  Accuracy:  38.88888955116272\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_tfidf.todense(), y_test, verbose=0)\n",
    "print(\"Loss: \", test_loss*100, \" | \", \"Accuracy: \", test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 - Word Vectors\n",
    "\n",
    "Word-Vectors is a dense representation of words in the form of numeric vectors. It can be learned using a variety of language models.\n",
    "\n",
    "![title](images/word_2_vec_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can downlaod using GoogleNews Vectors using the following commands in your LinuxOS shell: \n",
    "\n",
    "brew install wget\n",
    "\n",
    "wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\"/home/rayyan/Projects/KYAK/Data/google_news_vectors/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vec(text):\n",
    "    text_vec = np.sum(np.array([word_vectors[word] for word in text.split() if word in word_vectors.vocab]), axis=0)\n",
    "    if type(text_vec) is np.float64:\n",
    "        return pd.Series([0 for val in range(300)])\n",
    "\n",
    "    return pd.Series(text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_cols = [str(val) for val in range(300)]\n",
    "for v_c in vec_cols:\n",
    "    final_data[v_c] = 0\n",
    "final_data[vec_cols] = final_data.text.apply(text_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>The storm before the calm before the storm • S...</td>\n",
       "      <td>0.608</td>\n",
       "      <td>8.374574</td>\n",
       "      <td>8.622639</td>\n",
       "      <td>4.300964</td>\n",
       "      <td>9.244730</td>\n",
       "      <td>-4.353531</td>\n",
       "      <td>-8.544533</td>\n",
       "      <td>-0.882080</td>\n",
       "      <td>-11.943550</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.493273</td>\n",
       "      <td>-10.428246</td>\n",
       "      <td>-22.988541</td>\n",
       "      <td>3.305084</td>\n",
       "      <td>4.089558</td>\n",
       "      <td>-9.668156</td>\n",
       "      <td>-3.452728</td>\n",
       "      <td>-7.243034</td>\n",
       "      <td>3.833265</td>\n",
       "      <td>-2.418930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>What Lessons America Can Learn From This Elect...</td>\n",
       "      <td>0.953</td>\n",
       "      <td>8.519592</td>\n",
       "      <td>5.978402</td>\n",
       "      <td>5.369186</td>\n",
       "      <td>16.759216</td>\n",
       "      <td>-10.465744</td>\n",
       "      <td>-1.090652</td>\n",
       "      <td>7.388054</td>\n",
       "      <td>-9.830246</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.213850</td>\n",
       "      <td>-0.607891</td>\n",
       "      <td>-14.762993</td>\n",
       "      <td>-0.198021</td>\n",
       "      <td>-6.634659</td>\n",
       "      <td>-6.770321</td>\n",
       "      <td>-0.042440</td>\n",
       "      <td>-3.687212</td>\n",
       "      <td>5.635551</td>\n",
       "      <td>-4.302097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>New Heavy-Duty Voting Machine Allows Americans...</td>\n",
       "      <td>0.384</td>\n",
       "      <td>8.402206</td>\n",
       "      <td>10.366974</td>\n",
       "      <td>-2.172836</td>\n",
       "      <td>2.865843</td>\n",
       "      <td>-8.216553</td>\n",
       "      <td>-1.899935</td>\n",
       "      <td>-1.428459</td>\n",
       "      <td>-13.520512</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.197464</td>\n",
       "      <td>-12.738144</td>\n",
       "      <td>-22.096054</td>\n",
       "      <td>-1.872210</td>\n",
       "      <td>-3.452843</td>\n",
       "      <td>-9.886845</td>\n",
       "      <td>0.684963</td>\n",
       "      <td>-9.567497</td>\n",
       "      <td>3.004120</td>\n",
       "      <td>-6.191963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>By Daily News Bin | November 3, 2016 | 2 947 S...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8.767174</td>\n",
       "      <td>9.646676</td>\n",
       "      <td>9.507690</td>\n",
       "      <td>12.123718</td>\n",
       "      <td>-18.586260</td>\n",
       "      <td>-7.115929</td>\n",
       "      <td>5.289146</td>\n",
       "      <td>-12.252220</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.705093</td>\n",
       "      <td>-3.308319</td>\n",
       "      <td>-19.682428</td>\n",
       "      <td>9.614758</td>\n",
       "      <td>-7.791946</td>\n",
       "      <td>-3.699747</td>\n",
       "      <td>3.111159</td>\n",
       "      <td>-0.965698</td>\n",
       "      <td>9.978531</td>\n",
       "      <td>-3.822708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>Страна: Ирак Как отмечает в своей новой статье...</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>-1.706888</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.396240</td>\n",
       "      <td>-1.113708</td>\n",
       "      <td>0.896606</td>\n",
       "      <td>1.082916</td>\n",
       "      <td>-0.494751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700562</td>\n",
       "      <td>1.233398</td>\n",
       "      <td>-1.367432</td>\n",
       "      <td>-0.323242</td>\n",
       "      <td>0.426849</td>\n",
       "      <td>-1.473541</td>\n",
       "      <td>-3.104736</td>\n",
       "      <td>-0.072449</td>\n",
       "      <td>-0.042725</td>\n",
       "      <td>3.070801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam_score         0  \\\n",
       "1063  The storm before the calm before the storm • S...       0.608  8.374574   \n",
       "1144  What Lessons America Can Learn From This Elect...       0.953  8.519592   \n",
       "1092  New Heavy-Duty Voting Machine Allows Americans...       0.384  8.402206   \n",
       "660   By Daily News Bin | November 3, 2016 | 2 947 S...       0.200  8.767174   \n",
       "861   Страна: Ирак Как отмечает в своей новой статье...       0.219  0.036377   \n",
       "\n",
       "              1         2          3          4         5         6  \\\n",
       "1063   8.622639  4.300964   9.244730  -4.353531 -8.544533 -0.882080   \n",
       "1144   5.978402  5.369186  16.759216 -10.465744 -1.090652  7.388054   \n",
       "1092  10.366974 -2.172836   2.865843  -8.216553 -1.899935 -1.428459   \n",
       "660    9.646676  9.507690  12.123718 -18.586260 -7.115929  5.289146   \n",
       "861   -1.706888  0.910156   0.396240  -1.113708  0.896606  1.082916   \n",
       "\n",
       "              7  ...        290        291        292       293       294  \\\n",
       "1063 -11.943550  ...  -9.493273 -10.428246 -22.988541  3.305084  4.089558   \n",
       "1144  -9.830246  ... -14.213850  -0.607891 -14.762993 -0.198021 -6.634659   \n",
       "1092 -13.520512  ... -13.197464 -12.738144 -22.096054 -1.872210 -3.452843   \n",
       "660  -12.252220  ... -20.705093  -3.308319 -19.682428  9.614758 -7.791946   \n",
       "861   -0.494751  ...   0.700562   1.233398  -1.367432 -0.323242  0.426849   \n",
       "\n",
       "           295       296       297       298       299  \n",
       "1063 -9.668156 -3.452728 -7.243034  3.833265 -2.418930  \n",
       "1144 -6.770321 -0.042440 -3.687212  5.635551 -4.302097  \n",
       "1092 -9.886845  0.684963 -9.567497  3.004120 -6.191963  \n",
       "660  -3.699747  3.111159 -0.965698  9.978531 -3.822708  \n",
       "861  -1.473541 -3.104736 -0.072449 -0.042725  3.070801  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Before moving forward lets split our dataset into train and test in order to train a prediction model and its evaluation. Lets pick a 15% test dataset and keep 85% for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word_vec, X_test_word_vec, y_train_word_vec, y_test_word_vec = train_test_split(final_data[vec_cols].values, final_data[\"spam_score\"].values, test_size=0.15, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1117, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Compling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(3, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizers=\"sgd\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1117 samples\n",
      "Epoch 1/10\n",
      "1117/1117 [==============================] - 0s 47us/sample - loss: 0.0879 - accuracy: 0.4199\n",
      "Epoch 2/10\n",
      "1117/1117 [==============================] - 0s 40us/sample - loss: 0.0879 - accuracy: 0.4199\n",
      "Epoch 3/10\n",
      "1117/1117 [==============================] - 0s 38us/sample - loss: 0.0878 - accuracy: 0.4199\n",
      "Epoch 4/10\n",
      "1117/1117 [==============================] - 0s 38us/sample - loss: 0.0877 - accuracy: 0.4199\n",
      "Epoch 5/10\n",
      "1117/1117 [==============================] - 0s 40us/sample - loss: 0.0878 - accuracy: 0.4199\n",
      "Epoch 6/10\n",
      "1117/1117 [==============================] - 0s 39us/sample - loss: 0.0876 - accuracy: 0.4199\n",
      "Epoch 7/10\n",
      "1117/1117 [==============================] - 0s 42us/sample - loss: 0.0872 - accuracy: 0.4199\n",
      "Epoch 8/10\n",
      "1117/1117 [==============================] - 0s 42us/sample - loss: 0.0873 - accuracy: 0.4199\n",
      "Epoch 9/10\n",
      "1117/1117 [==============================] - 0s 35us/sample - loss: 0.0875 - accuracy: 0.4199\n",
      "Epoch 10/10\n",
      "1117/1117 [==============================] - 0s 37us/sample - loss: 0.0872 - accuracy: 0.4199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80da8d6320>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_word_vec, y_train_word_vec, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  9.978104081719813  |  Accuracy:  38.88888955116272\n"
     ]
    }
   ],
   "source": [
    "test_loss_vec, test_acc_vec = model.evaluate(X_test_word_vec, y_test_word_vec, verbose=0)\n",
    "print(\"Loss: \", test_loss_vec*100, \" | \", \"Accuracy: \", test_acc_vec*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
